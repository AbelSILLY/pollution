---
title: "Étude de la pollution de l'air en Occitanie"
author: "Ibrahim ATTOUMANI, Tristan RIVALDI, Kilian SAINT-CHÉlY, Abel SILLY, Jeanne VIVIER"
format: 
    revealjs :
        transition: slide
        background-transition: fade
---

# Introduction

## 

![](cycles-pollution.png)


- Comment évolue la pollution de l'air en Occitanie ?


## But de l'étude 

- Quels sont les principaux polluants ?
    -  Apprivoisement du sujet
    - La première prise en main des données

- Une répartition inégale en Occitanie ? 
    - Découpage progressif de la carte
    - Choix des données
    - Choix des représentations

- L'influence de la météo
    - Comparaison des graphiques


# Arborescence du projet


## Module Modpollution

- Modpollution
    - data
        - fichiers .csv
        - fichiers .json
    
    Sous modules
    - io: import de données avec Load
    - traitement : fonctions de traitement des données
    - vis : fonctions de visualisation
    


## Les données

- pollution:
    - annuelles (2018-2023)
    - mensuelles (2022-2023)
    - journalières (2022-2023)
    - horaire (dernier mois)
    - indice de pollution
- météo:
    - Montpellier (2022-2023)
    - Toulouse (2022-2023)
    - Hautes-Pyrénées (2022-2023)




## io
- Classe Load 
    - requests (pooch aurait fonctionné)
    - initialisation avec les url de données et chemin vers 'data'
    - écrit le contenu des fichiers en binaire pour problème d'encodage

 <br/>

```{.python}
fname_mcsv = 'data_m.csv'
data_mcsv = requests.get(url_mcsv)
with open(os.path.join(path_target,fname_mcsv),'wb') as output_file:
        output_file.write(data_mcsv.content)
```

## Traitement


```{.python}
def as_df(data_path_target):
    with open(data_path_target) as f:
     data = json.load(f)
    
    features = data['features']
    data_list = []

    for feature in features:
        data_list.append(feature['attributes'])

    df_raw = pd.DataFrame(data_list)
    df = df_raw.dropna()
    return df


```
    
 <br/>
 
 <br/>   
    

```{.python}
def extraire_donnees_station(donnees, station):
    df = donnees.loc[(donnees["nom_station"] == station), ["nom_poll", "valeur", "date_debut", "nom_station"]]
    return df

```


# L'affichage
    - plotly
    - geopandas
    - folium

```{.python}
def plotpoll(df):
    vmin=np.min(df['valeur'])
    vmax=np.max(df['valeur'])
    tmin = np.min(df["date_debut"])
    tmax=  np.max(df["date_debut"])
    fig = px.scatter(
        df,
        x = "date_debut",
        y = "valeur",
        animation_frame = 'date_debut',
        animation_group = 'nom_poll',
        color="nom_poll",
        range_x=[tmin, tmax],#pour bien se placer sur le graphe
        range_y=[vmin-5, vmax+5],
        size='valeur'
    )
    fig.show("notebook")
```

## Graphiques

```{python}
#| echo: false
import pandas as pd
import sys
sys.path.append('../')
import modpollution
df_a = pd.read_csv("../modpollution/data/data_a.csv")
df_a = modpollution.modif_date_csv(df_a,True)
df_a = modpollution.extraire_donnees_villes(df_a,'TOULOUSE')
df_a = modpollution.mean_df(df_a)
modpollution.plotpoll(df_a)
```

##
```{.python}
... 
fig = px.line(df, x='Year', y='Concentration', color='Pollutant', markers=True, line_group='Pollutant',
              labels={'Concentration': 'Concentration', 'Year': 'Année'},
              title='Concentration des polluants à Toulouse par année',
              template='plotly', height=600)
# Ajouter un curseur pour filtrer les données par année
fig.update_layout(
    xaxis=dict(
        rangeslider=dict(
            visible=True
        ),
        type='linear'  
    )
)

fig.show()
```
##
```{python}
#| echo: false
import requests
import pandas as pd
import plotly.express as px
from datetime import datetime
from collections import defaultdict

# URL de l'API GeoJSON pour Toulouse
url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/mesures_occitanie_annuelle_poll_princ/FeatureServer/0/query?outFields=*&where=nom_com='TOULOUSE'&f=geojson"

# Récupérer les données GeoJSON depuis l'API
response = requests.get(url)
data = response.json()

# Extraire les données pertinentes pour Toulouse
features = data['features']
toulouse_data = [feature['properties'] for feature in features]

# Préparer les données pour le tracé
pollutants_per_year = defaultdict(list)

for entry in toulouse_data:
    pollutant = entry['nom_poll']
    concentration = entry['valeur']
    date_debut_timestamp = entry['date_debut']
    year = datetime.utcfromtimestamp(date_debut_timestamp / 1000).year

    pollutants_per_year[pollutant].append((year, concentration))

# Transformer les données pour le tracé (calculer la concentration moyenne par année)
for pollutant, data in pollutants_per_year.items():
    data.sort(key=lambda x: x[0])

    # Calculer les concentrations moyennes par année
    averages_per_year = defaultdict(float)
    counts_per_year = defaultdict(int)

    for year, concentration in data:
        if concentration is not None:
            averages_per_year[year] += concentration
            counts_per_year[year] += 1

    for year in averages_per_year:
        if counts_per_year[year] > 0:
            averages_per_year[year] /= counts_per_year[year]

    pollutants_per_year[pollutant] = list(averages_per_year.items())

# Créer un DataFrame pour Plotly Express
df = pd.DataFrame([(pollutant, year, concentration) for pollutant, data in pollutants_per_year.items() for year, concentration in data],
                  columns=['Pollutant', 'Year', 'Concentration'])

# Tracé avec Plotly Express
fig = px.line(df, x='Year', y='Concentration', color='Pollutant', markers=True, line_group='Pollutant',
              labels={'Concentration': 'Concentration', 'Year': 'Année'},
              title='Concentration des polluants à Toulouse par année',
              template='plotly', height=600)

# Personnaliser le tracé pour ressembler à Matplotlib
fig.update_traces(
    line=dict(width=1),  # Épaisseur de la ligne
    marker=dict(size=8)   # Taille des marqueurs
)

# Ajouter un curseur pour filtrer les données par année
fig.update_layout(
    xaxis=dict(
        rangeslider=dict(
            visible=True
        ),
        type='linear'  # Assurez-vous que le type d'axe x est 'linear' pour que le curseur fonctionne
    )
)

# Afficher le tracé interactif
fig.show()

```



## Cartes
- Cartes choroplates

```{python}
#| echo: false

import pandas as pd
import geopandas as gpd
import matplotlib.pyplot as plt
import folium
import requests
import warnings 
warnings.filterwarnings("ignore")

# initialisation d'un dataframe à partir d'un fichier local contenant les géométries (polygone) de l'Occitanie
couche = gpd.read_file("../modpollution/data/polyg_geom.geojson")

# Définir l'URL
url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/Indice_quotidien_de_qualité_de_l’air_pour_les_collectivités_territoriales_en_Occitanie/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"
# url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/mesures_occitanie_72h_poll_princ/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"

# Effectuer une requête pour récupérer les données GeoJSON
response = requests.get(url)
data = response.json()

# Créer un GeoDataFrame à partir des données GeoJSON
gdf = gpd.GeoDataFrame.from_features(data['features'])

# gdf = gdf.merge(couche[['geometry']], left_index=True, right_index=True, suffixes=('', '_couche'))
# geopollu = gdf.rename(columns={'geometry_couche': 'polyg_geom'})

# On assigne les colones 'geometry' et 'nom_officiel_departement' au geodataframe gdf
gdf = gdf.assign(geometry=couche['geometry'])
gdf = gdf.assign(nom_officiel_departement=couche['nom_officiel_departement'])

# Afficher les premières lignes du GeoDataFrame
gdf.head()


# Créer une figure avec deux sous-plots côte à côte
fig, axs = plt.subplots(1, 2, figsize=(10, 5))

# Plot 1 : Carte avec la colonne 'code_o3'
axs[0].set_title('Concentration du polluant O3')
gdf.plot(column='code_o3', cmap='Spectral', linewidth=0.8, ax=axs[0], edgecolor='0.8', legend=True)

# Ajouter des étiquettes pour chaque département
for x, y, label in zip(gdf.geometry.centroid.x, gdf.geometry.centroid.y, gdf['nom_officiel_departement']):
    axs[0].annotate(label, xy=(x, y), xytext=(3, 3), textcoords='offset points')

# Plot 2 : Carte avec la colonne 'code_pm10'
axs[1].set_title('Concentration du polluant PM10')
gdf.plot(column='code_pm10', cmap='Spectral', linewidth=0.8, ax=axs[1], edgecolor='0.8', legend=True)

# Ajouter des étiquettes pour chaque département
for x, y, label in zip(gdf.geometry.centroid.x, gdf.geometry.centroid.y, gdf['nom_officiel_departement']):
    axs[1].annotate(label, xy=(x, y), xytext=(3, 3), textcoords='offset points')

# Ajuster l'espacement entre les sous-plots
plt.tight_layout()

# Afficher les plots
for ax in axs:
    ax.axis("off")
plt.show()
```


## Cartes
- Carte interactive

```{python}
#| echo: false

import requests
import folium
from datetime import datetime
from IPython.display import display
import os
import warnings 
warnings.filterwarnings("ignore")

# Récupérer les données depuis l'URL
url = "https://services9.arcgis.com/7Sr9Ek9c1QTKmbwr/arcgis/rest/services/epipol_occitanie/FeatureServer/0/query?outFields=*&where=1%3D1&f=geojson"
response = requests.get(url)
data = response.json()

# Créer une carte centrée sur une position approximative en Occitanie
m = folium.Map(location=[43.6, 1.4], zoom_start=8)

# Créer un dictionnaire pour stocker le nombre d'alertes et les dates associées à chaque point
alerts_by_location = {}

# Ajouter des marqueurs rouges pour chaque alerte avec le nombre d'alertes, la date et le polluant responsable
features = data.get('features', [])
for feature in features:
    properties = feature.get('properties', {})
    geometry = feature.get('geometry', {})
    coordinates = geometry.get('coordinates', [])
    etat = properties.get('etat', '')
    date_ech = properties.get('date_ech', '')
    lib_zone = properties.get('lib_zone', '')
    lib_pol = properties.get('lib_pol', '')  # Ajout du polluant responsable

    # Vérifier si l'état est une alerte et si la date est présente
    if etat == 'ALERTE' and date_ech:
        date_str = datetime.fromtimestamp(date_ech / 1000).strftime('%m/%d/%Y')

        # Ajouter le nombre d'alertes, la date et le polluant responsable au dictionnaire associé aux coordonnées
        if tuple(coordinates) in alerts_by_location:
            alerts_by_location[tuple(coordinates)]['count'] += 1
            alerts_by_location[tuple(coordinates)]['dates'].append(f"{date_str} ({lib_pol})")
        else:
            alerts_by_location[tuple(coordinates)] = {'count': 1, 'dates': [f"{date_str} ({lib_pol})"], 'lib_zone': lib_zone}

# Ajouter des marqueurs pour chaque point avec une taille de marqueur variable en fonction du nombre d'alertes
for coordinates, alert_info in alerts_by_location.items():
    count = alert_info['count']
    lib_zone = alert_info['lib_zone']
    dates = "<br>".join(alert_info['dates'])

    # La taille du marqueur est définie par le nombre d'alertes
    radius = count * 2  # Vous pouvez ajuster le facteur de multiplication pour obtenir la taille désirée

    popup_text = f"Nombre d'alertes : {count}<br>Dates : {dates}<br>Département : {lib_zone}"
    
    # Créer le marqueur avec une taille variable
    folium.CircleMarker(location=[coordinates[1], coordinates[0]], radius=radius, popup=popup_text, color='red', fill=True).add_to(m)

# Afficher la carte dans le notebook
display(m)
```


## Site Web
![](siteaccueil.png)

## 
![](siteville.png)

##
![](toulouse.png)

# Github et IDE
![](githubimage.png)

# Attentes et réalité

## Utilisation d'un jeu de données supplémentaire

```{python}

import matplotlib.pyplot as plt

# Données à afficher
labels = ['Résidentiel/Tertiaire', 'Transport routier', 'Industrie manufacturière', 'Agriculture', 'Transformation de l\'énergie', 'Autre']
pourcentages = [62, 17, 11, 6, 2, 2]

# Couleurs
colors = plt.cm.Paired(range(len(labels)))

# Création du graphique en forme de donuts
fig, ax = plt.subplots()
wedges, texts, autotexts = ax.pie(pourcentages, labels=None, autopct='', startangle=90, colors=colors)

# Ajout des pourcentages sans chevauchement
for i, (text, autotext) in enumerate(zip(texts, autotexts)):
    angle = wedges[i].theta2 - wedges[i].theta1
    if angle >= 10:  # Éviter l'affichage des pourcentages pour les petits segments
        x, y = autotext.get_position()
        distance = 1.15  # Facteur d'espacement des pourcentages
        ax.text(x * distance, y * distance, '{:.1f}%'.format(pourcentages[i]), ha='center', va='center')

# Dessiner un cercle au centre pour transformer le pie chart en donut chart
centre_cercle = plt.Circle((0, 0), 0.70, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_cercle)

# Ajout de la légende
legend_labels = ['{} - {:.1f}%'.format(label, percentage) for label, percentage in zip(labels, pourcentages)]
ax.legend(wedges, legend_labels, title="Secteurs d'activité", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

# Ajustements
ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.suptitle('D\'après le ministère de l\'environnment', fontstyle='italic' )
plt.title('Origine des particules PM10 en France (2014)')

# Affichage du graphique
plt.show()


```

## {auto-animate=false}
```{python}
import matplotlib.pyplot as plt

# Données à afficher
labels = ['Résidentiel/Tertiaire', 'Transport routier', 'Industrie manufacturière', 'Agriculture', 'Transformation de l\'énergie', 'Autre']
pourcentages = [62, 17, 11, 6, 2, 2]

# Couleurs avec transparence (alpha)
colors = [(0.8, 0.8, 0.8, 0.6), (0.8, 0.8, 0.8, 0.6), (0.8, 0.8, 0.8, 0.6), (0.8, 0.8, 0.8, 0.6), (1.0, 0.65, 0.0, 0.8), (0.8, 0.8, 0.8, 0.6)]  # Opacité réduite pour tous

# Création du graphique en forme de donuts
fig, ax = plt.subplots()
wedges, texts, autotexts = ax.pie(pourcentages, labels=None, autopct='', startangle=90, colors=colors)

# Ajout des pourcentages sans chevauchement
for i, (text, autotext) in enumerate(zip(texts, autotexts)):
    angle = wedges[i].theta2 - wedges[i].theta1
    if angle >= 10:  # Éviter l'affichage des pourcentages pour les petits segments
        x, y = autotext.get_position()
        distance = 1.15  # Facteur d'espacement des pourcentages
        ax.text(x * distance, y * distance, '{:.1f}%'.format(pourcentages[i]), ha='center', va='center')

# Dessiner un cercle au centre pour transformer le pie chart en donut chart
centre_cercle = plt.Circle((0, 0), 0.70, fc='white')
fig = plt.gcf()
fig.gca().add_artist(centre_cercle)

# Ajout de la légende
legend_labels = ['{} - {:.1f}%'.format(label, percentage) for label, percentage in zip(labels, pourcentages)]
ax.legend(wedges, legend_labels, title="Secteurs d'activité", loc="center left", bbox_to_anchor=(1, 0, 0.5, 1))

# Ajustements
ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.
plt.suptitle('D\'après le ministère de l\'environnement', fontstyle='italic' )
plt.title('Origine des particules PM10 en France (2014)')

# Affichage du graphique
plt.show()
```

## Production d'électricité en Occitanie

![](rte.png)




L'utilisation des données de RTE ne nous a pas semblé si pertinante...      
 _Source : RTE, production d'électricité en 2022 en Occitanie_     


## Respecter nos idéaux

|   Nos attentes|   Réussi &#x1F600; |  Raté &#128542;|
|---    |:-:    |:-:  |
|  Faire des réunions régulières   |   &#10003;   |
|  Ne pas travailler dans l'urgence    |    |   &#x274C; |   
|  Répartir le travail  |   &#10003;   |   | 
|  Être efficaces  |     |   &#x274C; |   
|  Utiliser les outils vus en cours   |   &#10003;  |   |


- Satisfaction moyenne

## Les difficultés...

- Liées au projet
    - Appréhender le sujet correctement 
    - Organiser les idées et le travail
    - Éviter le travail inutile
    - Coodroner un groupe
    - Temps de travail

![](groupe.png)

## Les difficultés...

- Informatiques
    - La prise en main des outils proposés
    - Apprentissages personnels 
    - Les données météo
    - Les url et fichiers csv

![](ordi.png)

# Conclusion 

## 
- Ce qu'on retiendra pour l'avenir
    - Des bases solides dans l'utilisation de GitHub
    - Une meilleure organisation 
    - Le sujet de l'étude était intéressant

- Ce qu'on aurait pu améliorer
    - Utilser des tests
    - Faire une documentation
    - Une classe supplémentaire pour le traitement
